{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import itertools\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import KFold\n\n# import IRIS dataset to play with\niris = datasets.load_iris()\n\ndata = iris.data\ntarget = iris.target\n\ndata.shape\n# Data description\nprint(iris.DESCR)\nclass_names = iris.target_names\nclass_names\nlabels, counts = np.unique(target, return_counts=True)\n\n\ndef evaluate_model(data_x, data_y):\n    k_fold = KFold(12, shuffle=True, random_state=1)\n\n    predicted_targets = np.array([])\n    actual_targets = np.array([])\n    accuracy_list = list()\n\n    for train_ix, test_ix in k_fold.split(data_x):\n        train_x, train_y, test_x, test_y = data_x[train_ix], data_y[train_ix], data_x[test_ix], data_y[test_ix]\n\n        # Fit the classifier\n        classifier = svm.SVC().fit(train_x, train_y)\n\n        # Predict the labels of the test set samples\n        predicted_labels = classifier.predict(test_x)\n        accuracy = accuracy_score(test_y, predicted_labels)\n\n        predicted_targets = np.append(predicted_targets, predicted_labels)\n        actual_targets = np.append(actual_targets, test_y)\n        accuracy_list.append(accuracy)\n\n    return predicted_targets, actual_targets, accuracy_list\n\n\ndef plot_confusion_matrix(predicted_labels_list, y_test_list):\n    cnf_matrix = confusion_matrix(y_test_list, predicted_labels_list)\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    plt.figure()\n    generate_confusion_matrix(\n        cnf_matrix, classes=class_names, title='Confusion matrix but not normalized')\n    plt.show()\n\n    # Plot normalized confusion matrix\n    plt.figure()\n    generate_confusion_matrix(cnf_matrix, classes=class_names,\n                              normalize=True, title='Normalized confusion matrix')\n    plt.show()\n\n\ndef generate_confusion_matrix(cnf_matrix, classes, normalize=False, title='Confusion matrix'):\n    if normalize:\n        cnf_matrix = cnf_matrix.astype(\n            'float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix but not normalized')\n\n    plt.imshow(cnf_matrix, interpolation='nearest', cmap=plt.get_cmap('Reds'))\n    plt.title(title)\n    plt.colorbar()\n\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cnf_matrix.max() / 2.\n\n    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n        plt.text(j, i, format(cnf_matrix[i, j], fmt), horizontalalignment=\"center\",\n                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    return cnf_matrix\n\n\npredicted_target, actual_target, accuracy_list = evaluate_model(data, target)\nplot_confusion_matrix(predicted_target, actual_target)\nprint(\"Mean accuracy:\", np.mean(accuracy_list))\nprint(\"Standard deviation of accuracy:\", np.std(accuracy_list))\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}